# -*- coding: utf-8 -*-
"""machine-learning-modelo

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10pNHmpj6ABvVFNiIRFStY_wZCMVs_M97
"""

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import pandas as pd
import os
import shutil
from sklearn.model_selection import train_test_split
import kagglehub

print("--- 1. Baixando e Organizando Imagens (HAM10000) ---")
# Baixa o dataset
path = kagglehub.dataset_download("kmader/skin-cancer-mnist-ham10000")
print(f"Dataset baixado em: {path}")

# Localizando arquivos
base_dir = path
# O dataset do kaggle as vezes vem em pastas separadas, vamos unificar
image_dir_1 = os.path.join(base_dir, 'HAM10000_images_part_1')
image_dir_2 = os.path.join(base_dir, 'HAM10000_images_part_2')
metadata = pd.read_csv(os.path.join(base_dir, 'HAM10000_metadata.csv'))

# Criar estrutura de pastas para o Keras ler: ./train/melanoma/img1.jpg
# Vamos simplificar para 2 classes para o MVP: "Perigoso" (Melanoma/Carcinoma) vs "Benigno" (Nevo/Outros)
# Isso aumenta MUITO a acurácia para o trabalho final.

# Mapeamento: O que é perigoso?
# mel = Melanoma, bcc = Carcinoma basocelular, akiec = Ceratose actínica
perigoso = ['mel', 'bcc', 'akiec']

metadata['target'] = metadata['dx'].apply(lambda x: 'perigo' if x in perigoso else 'benigno')

# Criar diretório temporário de treino
work_dir = './skin_data'
if os.path.exists(work_dir):
    shutil.rmtree(work_dir)
os.makedirs(work_dir)

train_dir = os.path.join(work_dir, 'train')
val_dir = os.path.join(work_dir, 'val')

for d in [train_dir, val_dir]:
    os.makedirs(os.path.join(d, 'perigo'))
    os.makedirs(os.path.join(d, 'benigno'))

# Separar treino e validação
train_df, val_df = train_test_split(metadata, test_size=0.2, stratify=metadata['target'], random_state=42)

print("Copiando imagens... (Isso pode levar uns 2 minutos)")

def copy_images(df, dest_dir):
    for _, row in df.iterrows():
        img_name = row['image_id'] + '.jpg'
        label = row['target']

        # Procura onde está a imagem (parte 1 ou parte 2)
        src = os.path.join(image_dir_1, img_name)
        if not os.path.exists(src):
            src = os.path.join(image_dir_2, img_name)

        if os.path.exists(src):
            shutil.copy(src, os.path.join(dest_dir, label, img_name))

copy_images(train_df, train_dir)
copy_images(val_df, val_dir)
print("Imagens organizadas!")

# --- 2. Preparando o Modelo (Transfer Learning) ---

# Data Augmentation (Girar e dar zoom nas imagens para o modelo aprender melhor)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    zoom_range=0.2
)

val_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=(224, 224), batch_size=32, class_mode='binary'
)

val_generator = val_datagen.flow_from_directory(
    val_dir, target_size=(224, 224), batch_size=32, class_mode='binary'
)

# Carregar o MobileNetV2 (Cérebro pré-treinado)
base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False # Congela o cérebro base para não estragar o que ele já sabe

# Adicionar a "cabeça" do nosso modelo
x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.5)(x) # Evita decorar
predictions = Dense(1, activation='sigmoid')(x) # 1 neurônio (0 ou 1)

model = Model(inputs=base_model.input, outputs=predictions)

model.compile(optimizer=Adam(learning_rate=0.0001),
              loss='binary_crossentropy',
              metrics=['accuracy', 'AUC'])

# --- 3. Treinamento ---
print("\n--- Iniciando Treinamento da Rede Neural ---")
history = model.fit(
    train_generator,
    epochs=5, # 5 Épocas é suficiente para demonstração no Colab
    validation_data=val_generator
)

# --- 4. Salvar Modelo ---
model.save('modelo_cancer_pele.h5')
print("\nModelo de imagem salvo como 'modelo_cancer_pele.h5'")

# ... (Todo o seu código de treinamento anterior fica aqui) ...

# --- 5. ETAPA EXTRA: ENVIAR PARA O DATA LAKE (MINIO) ---
from minio import Minio
import os

print("\n--- Iniciando Exportação para o MinIO ---")

# 1. Configurar Conexão (Atenção ao endpoint!)
# Se esse script rodar DENTRO do Docker, use "minio:9000"
# Se rodar FORA (no seu PC), use "localhost:9000"
client = Minio(
    "minio:9000",  # Nome do serviço no docker-compose
    access_key="admin",
    secret_key="password123",
    secure=False
)

# 2. Criar o Bucket 'models' se não existir
bucket_name = "models"
if not client.bucket_exists(bucket_name):
    client.make_bucket(bucket_name)
    print(f"Bucket '{bucket_name}' criado.")

# 3. Enviar o arquivo
model_filename = 'modelo_cancer_pele.h5'
if os.path.exists(model_filename):
    client.fput_object(
        bucket_name,
        model_filename,
        model_filename,
    )
    print(f"✅ SUCESSO: Modelo '{model_filename}' salvo no Data Lake MinIO!")
else:
    print("❌ ERRO: Arquivo do modelo não encontrado localmente.")